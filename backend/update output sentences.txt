def preprocessing_text(sentences, aspect):
  # hapus url
  sentences = re.sub('\S+.com|\S+.co.id|\S+.co|\S+.id', '.', sentences)

  ### hapus titik yang bukan pemisah kalimat 
  ### (yang pemisah angka, Tbk., PT.)
  sentences = sentences.replace("PT.", "PT").replace("Tbk.", "Tbk")
  sentences = remove_unused_dots(sentences)

  ### Ambil kalimat yang mengandung emiten
  sentences = sentences.split('.')
  arr_sentence_dirt = clean_sentences(sentences, aspect)
  
  arr_sentence_clean = []
  i = 0
  while (i < (len(arr_sentence_dirt))):
    arr_sentence_clean[i] = re.sub(r'[^\w\d\s\.]+', '', arr_sentence_dirt[i]) 
    arr_sentence_clean[i] = arr_sentence_clean[i].lower()
    ### Menghapus angka
    arr_sentence_clean[i] = ''.join([x for x in arr_sentence_clean[i] if not x.isdigit()])
    i = i+1

  return arr_sentence_clean, arr_sentence_dirt 


arr_sentence_clean, arr_sentence_dirt  = preprocessing_text(s, aspect)
print(str(arr_sentence_clean))

i = 0
sentiments = ["Negative", "Neutral", "Positive"]
while (i < (len(arr_sentence_clean))):
  x, y, z = predict(arr_sentence_clean[i] , aspect, tokenizer)
  print("Sentence = " + arr_sentence_dirt[i])

  y_str = str(y)
  sentiment = sentiments[int(y_str[8])]
  print("Sentiment = " + sentiment)
  print("============================================")
  # print(x)
  # print(y)
  # print(z)
  i = i+1